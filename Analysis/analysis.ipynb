{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import itertools\n",
    "import holidays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data into dataframe -- energy prices for houston, north, south, and west load zones, predicted and actual energy load for all four load zones, and oil prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\achra\\OneDrive\\Documents\\GitHub\\ERCOT_Price_Prediction_Stat_413_Final_Project\\Data\\CombinedData2023.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>North Price</th>\n",
       "      <th>West Price</th>\n",
       "      <th>South Price</th>\n",
       "      <th>Houston Price</th>\n",
       "      <th>North Load</th>\n",
       "      <th>West Load</th>\n",
       "      <th>South Load</th>\n",
       "      <th>Houston Load</th>\n",
       "      <th>North Predicted Load</th>\n",
       "      <th>West Predicted Load</th>\n",
       "      <th>South Predicted Load</th>\n",
       "      <th>Houston Predicted Load</th>\n",
       "      <th>Oil Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/01/2023</td>\n",
       "      <td>00:00</td>\n",
       "      <td>-2.1200</td>\n",
       "      <td>-2.0200</td>\n",
       "      <td>-2.1100</td>\n",
       "      <td>-2.1150</td>\n",
       "      <td>11118.248963</td>\n",
       "      <td>7102.853761</td>\n",
       "      <td>8891.418391</td>\n",
       "      <td>8578.637876</td>\n",
       "      <td>14210.616112</td>\n",
       "      <td>7615.188874</td>\n",
       "      <td>10261.255994</td>\n",
       "      <td>11152.307651</td>\n",
       "      <td>76.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/01/2023</td>\n",
       "      <td>01:00</td>\n",
       "      <td>-1.1500</td>\n",
       "      <td>-0.8950</td>\n",
       "      <td>-1.1250</td>\n",
       "      <td>-1.1375</td>\n",
       "      <td>11115.263857</td>\n",
       "      <td>7107.853761</td>\n",
       "      <td>8871.418391</td>\n",
       "      <td>8514.637876</td>\n",
       "      <td>14297.425469</td>\n",
       "      <td>7661.026271</td>\n",
       "      <td>10166.597073</td>\n",
       "      <td>11011.450533</td>\n",
       "      <td>76.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/01/2023</td>\n",
       "      <td>02:00</td>\n",
       "      <td>-1.1700</td>\n",
       "      <td>-1.1275</td>\n",
       "      <td>-1.1675</td>\n",
       "      <td>-1.1700</td>\n",
       "      <td>10855.755296</td>\n",
       "      <td>7031.047191</td>\n",
       "      <td>8779.863470</td>\n",
       "      <td>8345.632899</td>\n",
       "      <td>14375.662482</td>\n",
       "      <td>7669.107039</td>\n",
       "      <td>10155.831781</td>\n",
       "      <td>10867.511020</td>\n",
       "      <td>76.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/01/2023</td>\n",
       "      <td>03:00</td>\n",
       "      <td>-0.0175</td>\n",
       "      <td>0.0275</td>\n",
       "      <td>-0.0125</td>\n",
       "      <td>-0.0150</td>\n",
       "      <td>10641.477018</td>\n",
       "      <td>7012.444478</td>\n",
       "      <td>8589.953921</td>\n",
       "      <td>8125.706879</td>\n",
       "      <td>14610.251706</td>\n",
       "      <td>7720.992165</td>\n",
       "      <td>10144.531996</td>\n",
       "      <td>10957.793669</td>\n",
       "      <td>76.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/01/2023</td>\n",
       "      <td>04:00</td>\n",
       "      <td>-0.8125</td>\n",
       "      <td>-0.8125</td>\n",
       "      <td>-0.8125</td>\n",
       "      <td>-0.8125</td>\n",
       "      <td>10574.197398</td>\n",
       "      <td>7035.195182</td>\n",
       "      <td>8396.254102</td>\n",
       "      <td>7995.083655</td>\n",
       "      <td>14931.854721</td>\n",
       "      <td>7762.281965</td>\n",
       "      <td>10258.219673</td>\n",
       "      <td>11067.944014</td>\n",
       "      <td>76.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8756</th>\n",
       "      <td>12/31/2023</td>\n",
       "      <td>19:00</td>\n",
       "      <td>14.2950</td>\n",
       "      <td>15.0000</td>\n",
       "      <td>14.3675</td>\n",
       "      <td>14.3325</td>\n",
       "      <td>14151.533311</td>\n",
       "      <td>8620.619728</td>\n",
       "      <td>10715.416266</td>\n",
       "      <td>12189.507916</td>\n",
       "      <td>15460.690742</td>\n",
       "      <td>8021.642107</td>\n",
       "      <td>11972.059826</td>\n",
       "      <td>13026.298976</td>\n",
       "      <td>71.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8757</th>\n",
       "      <td>12/31/2023</td>\n",
       "      <td>20:00</td>\n",
       "      <td>12.6250</td>\n",
       "      <td>13.1925</td>\n",
       "      <td>11.9300</td>\n",
       "      <td>12.5375</td>\n",
       "      <td>13922.923678</td>\n",
       "      <td>8534.075954</td>\n",
       "      <td>10376.214504</td>\n",
       "      <td>11918.024426</td>\n",
       "      <td>15184.016847</td>\n",
       "      <td>8017.744551</td>\n",
       "      <td>11704.179439</td>\n",
       "      <td>12768.119151</td>\n",
       "      <td>71.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8758</th>\n",
       "      <td>12/31/2023</td>\n",
       "      <td>21:00</td>\n",
       "      <td>11.6700</td>\n",
       "      <td>13.0250</td>\n",
       "      <td>2.5550</td>\n",
       "      <td>10.2650</td>\n",
       "      <td>13726.395295</td>\n",
       "      <td>8542.625513</td>\n",
       "      <td>9989.361479</td>\n",
       "      <td>11634.439863</td>\n",
       "      <td>14843.335871</td>\n",
       "      <td>7935.433637</td>\n",
       "      <td>11288.477649</td>\n",
       "      <td>12528.756783</td>\n",
       "      <td>71.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8759</th>\n",
       "      <td>12/31/2023</td>\n",
       "      <td>22:00</td>\n",
       "      <td>11.2900</td>\n",
       "      <td>12.6325</td>\n",
       "      <td>2.5775</td>\n",
       "      <td>9.8925</td>\n",
       "      <td>13508.403724</td>\n",
       "      <td>8612.699674</td>\n",
       "      <td>9632.467050</td>\n",
       "      <td>11360.099483</td>\n",
       "      <td>14453.674783</td>\n",
       "      <td>7868.521980</td>\n",
       "      <td>10984.821975</td>\n",
       "      <td>12163.892862</td>\n",
       "      <td>71.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8760</th>\n",
       "      <td>12/31/2023</td>\n",
       "      <td>23:00</td>\n",
       "      <td>14.0200</td>\n",
       "      <td>15.4250</td>\n",
       "      <td>4.9525</td>\n",
       "      <td>12.5600</td>\n",
       "      <td>13307.524078</td>\n",
       "      <td>8569.140445</td>\n",
       "      <td>9271.157296</td>\n",
       "      <td>11096.765551</td>\n",
       "      <td>14291.067385</td>\n",
       "      <td>7817.406837</td>\n",
       "      <td>10640.570022</td>\n",
       "      <td>11877.670412</td>\n",
       "      <td>71.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8761 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date   Time  North Price  West Price  South Price  Houston Price  \\\n",
       "0     01/01/2023  00:00      -2.1200     -2.0200      -2.1100        -2.1150   \n",
       "1     01/01/2023  01:00      -1.1500     -0.8950      -1.1250        -1.1375   \n",
       "2     01/01/2023  02:00      -1.1700     -1.1275      -1.1675        -1.1700   \n",
       "3     01/01/2023  03:00      -0.0175      0.0275      -0.0125        -0.0150   \n",
       "4     01/01/2023  04:00      -0.8125     -0.8125      -0.8125        -0.8125   \n",
       "...          ...    ...          ...         ...          ...            ...   \n",
       "8756  12/31/2023  19:00      14.2950     15.0000      14.3675        14.3325   \n",
       "8757  12/31/2023  20:00      12.6250     13.1925      11.9300        12.5375   \n",
       "8758  12/31/2023  21:00      11.6700     13.0250       2.5550        10.2650   \n",
       "8759  12/31/2023  22:00      11.2900     12.6325       2.5775         9.8925   \n",
       "8760  12/31/2023  23:00      14.0200     15.4250       4.9525        12.5600   \n",
       "\n",
       "        North Load    West Load    South Load  Houston Load  \\\n",
       "0     11118.248963  7102.853761   8891.418391   8578.637876   \n",
       "1     11115.263857  7107.853761   8871.418391   8514.637876   \n",
       "2     10855.755296  7031.047191   8779.863470   8345.632899   \n",
       "3     10641.477018  7012.444478   8589.953921   8125.706879   \n",
       "4     10574.197398  7035.195182   8396.254102   7995.083655   \n",
       "...            ...          ...           ...           ...   \n",
       "8756  14151.533311  8620.619728  10715.416266  12189.507916   \n",
       "8757  13922.923678  8534.075954  10376.214504  11918.024426   \n",
       "8758  13726.395295  8542.625513   9989.361479  11634.439863   \n",
       "8759  13508.403724  8612.699674   9632.467050  11360.099483   \n",
       "8760  13307.524078  8569.140445   9271.157296  11096.765551   \n",
       "\n",
       "      North Predicted Load  West Predicted Load  South Predicted Load  \\\n",
       "0             14210.616112          7615.188874          10261.255994   \n",
       "1             14297.425469          7661.026271          10166.597073   \n",
       "2             14375.662482          7669.107039          10155.831781   \n",
       "3             14610.251706          7720.992165          10144.531996   \n",
       "4             14931.854721          7762.281965          10258.219673   \n",
       "...                    ...                  ...                   ...   \n",
       "8756          15460.690742          8021.642107          11972.059826   \n",
       "8757          15184.016847          8017.744551          11704.179439   \n",
       "8758          14843.335871          7935.433637          11288.477649   \n",
       "8759          14453.674783          7868.521980          10984.821975   \n",
       "8760          14291.067385          7817.406837          10640.570022   \n",
       "\n",
       "      Houston Predicted Load  Oil Price  \n",
       "0               11152.307651      76.87  \n",
       "1               11011.450533      76.87  \n",
       "2               10867.511020      76.87  \n",
       "3               10957.793669      76.87  \n",
       "4               11067.944014      76.87  \n",
       "...                      ...        ...  \n",
       "8756            13026.298976      71.89  \n",
       "8757            12768.119151      71.89  \n",
       "8758            12528.756783      71.89  \n",
       "8759            12163.892862      71.89  \n",
       "8760            11877.670412      71.89  \n",
       "\n",
       "[8761 rows x 15 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Oil Price'] = df['Oil Price'].ffill()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Preprocessing before training LSTM Model:\n",
    "\n",
    "    1) Need to engineer lags for all energy price columns, and all actual load columns. Lags will be 1 hour, 24 hours, and 168 hours for price columns, and  24 hours for load columns.\n",
    "    2) Need to create exponential moving average (EMA) mean price and EMA price standard deviation variables for north price, west price, south price, and houston price. \n",
    "    3) Need to generate pairwise differences between north, west, south, and houston prices, but using the lagged version (168 hours ago) as the actual variable\n",
    "    4) Remove first week of data due to lag features being null.\n",
    "    5) Delete predicted load columns, save the last week of predicted load values to replace actual load with for the test set.\n",
    "    6) Encode month cyclically as sin and cos values.\n",
    "    7) Encode day of the week cyclically as sin and cos values.\n",
    "    8) Add binary holiday column to indicate whether a price observation was during a holiday or not.\n",
    "    9) Use standard scaler to normalize all numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Engineering Lagged Features\n",
    "\n",
    "def create_lagged_features(df, price_cols_and_lags, load_cols_and_lags):\n",
    "    \"\"\"\n",
    "    Create lagged features for price and load columns.\n",
    "    price_cols_and_lags: dictionary with keys as column names and values as a list of lags\n",
    "    load_cols_and_lags: dictionary with keys as column names and values as a list oflags\n",
    "    \"\"\"\n",
    "    new_df = df.copy()\n",
    "    for col, lags in price_cols_and_lags.items():\n",
    "        for lag in lags:\n",
    "            new_df[f'{col}_lag{lag}'] = new_df[col].shift(lag)\n",
    "    \n",
    "    for col, lags in load_cols_and_lags.items():\n",
    "        for lag in lags:\n",
    "            new_df[f'{col}_lag{lag}'] = new_df[col].shift(lag)\n",
    "    \n",
    "    return new_df\n",
    "\n",
    "price_cols_and_lags = {col: [1,24,168] for col in ['North Price', 'Houston Price', 'South Price', 'West Price']}\n",
    "load_cols_and_lags = {col: [24] for col in ['North Load', 'Houston Load', 'South Load', 'West Load']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ema_mean_and_sd(df, ema_cols, span = 168):\n",
    "    \"\"\"\n",
    "        Create Exponential Moving Average (EMA) Mean and Exponential Moving Average Standard Deviation (SD) for specified columns.\n",
    "        Parameters:\n",
    "        df (pandas.DataFrame): The input DataFrame containing the data.\n",
    "        ema_cols (list of str): List of column names for which to calculate the EMA mean and SD.\n",
    "        span (int, optional): The span for the EMA calculation. Default is 168.\n",
    "        Returns:\n",
    "        pandas.DataFrame: A new DataFrame with the original columns and additional columns for EMA mean and SD for each specified column.\n",
    "    \"\"\"\n",
    "    new_df = df.copy()\n",
    "    for col in ema_cols:\n",
    "        new_df[f'{col}_ema_mean'] = new_df[col].ewm(span= span).mean()\n",
    "        new_df[f'{col}_ema_std'] = new_df[col].ewm(span= span).std()\n",
    "    \n",
    "    return new_df\n",
    "\n",
    "ema_cols = ['North Price', 'Houston Price', 'South Price', 'West Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   North Price  Houston Price  South Price  West Price  \\\n",
      "0           10             15           12          18   \n",
      "1           20             25           22          28   \n",
      "2           30             35           32          38   \n",
      "3           40             45           42          48   \n",
      "4           50             55           52          58   \n",
      "5           60             65           62          68   \n",
      "6           70             75           72          78   \n",
      "7           80             85           82          88   \n",
      "8           90             95           92          98   \n",
      "9          100            105          102         108   \n",
      "\n",
      "   North Price_Houston Price_diff_lag168  North Price_South Price_diff_lag168  \\\n",
      "0                                    NaN                                  NaN   \n",
      "1                                    NaN                                  NaN   \n",
      "2                                    NaN                                  NaN   \n",
      "3                                    NaN                                  NaN   \n",
      "4                                    NaN                                  NaN   \n",
      "5                                    NaN                                  NaN   \n",
      "6                                    NaN                                  NaN   \n",
      "7                                    NaN                                  NaN   \n",
      "8                                    NaN                                  NaN   \n",
      "9                                    NaN                                  NaN   \n",
      "\n",
      "   North Price_West Price_diff_lag168  Houston Price_South Price_diff_lag168  \\\n",
      "0                                 NaN                                    NaN   \n",
      "1                                 NaN                                    NaN   \n",
      "2                                 NaN                                    NaN   \n",
      "3                                 NaN                                    NaN   \n",
      "4                                 NaN                                    NaN   \n",
      "5                                 NaN                                    NaN   \n",
      "6                                 NaN                                    NaN   \n",
      "7                                 NaN                                    NaN   \n",
      "8                                 NaN                                    NaN   \n",
      "9                                 NaN                                    NaN   \n",
      "\n",
      "   Houston Price_West Price_diff_lag168  South Price_West Price_diff_lag168  \n",
      "0                                   NaN                                 NaN  \n",
      "1                                   NaN                                 NaN  \n",
      "2                                   NaN                                 NaN  \n",
      "3                                   NaN                                 NaN  \n",
      "4                                   NaN                                 NaN  \n",
      "5                                   NaN                                 NaN  \n",
      "6                                   NaN                                 NaN  \n",
      "7                                   NaN                                 NaN  \n",
      "8                                   NaN                                 NaN  \n",
      "9                                   NaN                                 NaN  \n",
      "     North Price  Houston Price  South Price  West Price  \\\n",
      "0      70.830840      84.202939    62.497014   73.338849   \n",
      "1      80.468866      38.965593    79.372015    7.277424   \n",
      "2      77.876304      60.939883    57.442978   37.734102   \n",
      "3      31.143600      14.715737    75.841623    4.352141   \n",
      "4      39.372635      97.215725     3.240344   70.897611   \n",
      "..           ...            ...          ...         ...   \n",
      "195    57.523400      38.436370    46.405816   60.398946   \n",
      "196    37.127676      65.046011    28.293698   90.817635   \n",
      "197    19.753547      54.838025    80.353514   19.842932   \n",
      "198    62.515866      84.047087    75.015709   48.896374   \n",
      "199    23.976809      72.930416    70.999948   56.123241   \n",
      "\n",
      "     North Price_Houston Price_diff_lag168  \\\n",
      "0                                      NaN   \n",
      "1                                      NaN   \n",
      "2                                      NaN   \n",
      "3                                      NaN   \n",
      "4                                      NaN   \n",
      "..                                     ...   \n",
      "195                             -17.745197   \n",
      "196                             -17.848862   \n",
      "197                              11.287529   \n",
      "198                              14.269490   \n",
      "199                             -44.328259   \n",
      "\n",
      "     North Price_South Price_diff_lag168  North Price_West Price_diff_lag168  \\\n",
      "0                                    NaN                                 NaN   \n",
      "1                                    NaN                                 NaN   \n",
      "2                                    NaN                                 NaN   \n",
      "3                                    NaN                                 NaN   \n",
      "4                                    NaN                                 NaN   \n",
      "..                                   ...                                 ...   \n",
      "195                           -57.362971                          -37.879612   \n",
      "196                            20.163752                          -23.099091   \n",
      "197                            -3.307005                          -12.788718   \n",
      "198                            -4.963461                          -75.507107   \n",
      "199                             5.081362                          -49.625817   \n",
      "\n",
      "     Houston Price_South Price_diff_lag168  \\\n",
      "0                                      NaN   \n",
      "1                                      NaN   \n",
      "2                                      NaN   \n",
      "3                                      NaN   \n",
      "4                                      NaN   \n",
      "..                                     ...   \n",
      "195                             -39.617774   \n",
      "196                              38.012615   \n",
      "197                             -14.594534   \n",
      "198                             -19.232951   \n",
      "199                              49.409621   \n",
      "\n",
      "     Houston Price_West Price_diff_lag168  South Price_West Price_diff_lag168  \n",
      "0                                     NaN                                 NaN  \n",
      "1                                     NaN                                 NaN  \n",
      "2                                     NaN                                 NaN  \n",
      "3                                     NaN                                 NaN  \n",
      "4                                     NaN                                 NaN  \n",
      "..                                    ...                                 ...  \n",
      "195                            -20.134415                           19.483358  \n",
      "196                             -5.250228                          -43.262843  \n",
      "197                            -24.076247                           -9.481713  \n",
      "198                            -89.776598                          -70.543646  \n",
      "199                             -5.297559                          -54.707179  \n",
      "\n",
      "[200 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "def create_pairwise_differences_and_lags(df, price_cols, lag = 168):\n",
    "    new_df = df.copy()\n",
    "    pairwise_price_combinations = list(itertools.combinations(price_cols, 2))\n",
    "    for price1, price2 in pairwise_price_combinations:\n",
    "        new_df[\"{}_{}_diff\".format(price1, price2)] = new_df[price1] - new_df[price2]\n",
    "        new_df[\"{}_{}_diff_lag{}\".format(price1, price2, lag)] = new_df[\"{}_{}_diff\".format(price1, price2)].shift(lag)\n",
    "        new_df.drop(labels = [\"{}_{}_diff\".format(price1, price2)], axis = 1, inplace = True)\n",
    "    return new_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_rows_with_missing_values(df, rows = 168):\n",
    "    \"\"\"\n",
    "    Delete rows with missing data due to adding lagged features.\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The input DataFrame containing the data.\n",
    "    rows (int, optional): The number of rows to delete. Default is 168.\n",
    "    Returns:\n",
    "    pandas.DataFrame: A new DataFrame with the specified number of rows deleted.\n",
    "    \"\"\"\n",
    "    new_df = df.copy()\n",
    "    new_df = new_df.iloc[rows:]\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_predicted_load(df, load_cols, predicted_load_cols, test_data_size):\n",
    "    \"\"\"\n",
    "    Delete the predicted load columns, but replace the last test_data_size rows from the actual load values with the corresponding predicted load values.\n",
    "    \"\"\"\n",
    "    new_df = df.copy()\n",
    "    for load_col, predicted_load_col in zip(load_cols, predicted_load_cols):\n",
    "        new_df.iloc[-test_data_size:, new_df.columns.get_loc(load_col)] = new_df.iloc[-test_data_size:,new_df.columns.get_loc(predicted_load_col)]\n",
    "    for predicted_load_col in predicted_load_cols:\n",
    "        new_df.drop(predicted_load_col, axis = 1, inplace = True)\n",
    "    return new_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_month(df):\n",
    "    \"\"\"\n",
    "    Encode the month as a cyclic feature\n",
    "    \"\"\"\n",
    "    new_df = df.copy()\n",
    "    new_df['month'] = pd.to_datetime(new_df['Date']).dt.month\n",
    "    new_df['month_sin'] = np.sin(2 * np.pi * new_df['month'] / 12)\n",
    "    new_df['month_cos'] = np.cos(2 * np.pi * new_df['month'] / 12)\n",
    "    new_df.drop(labels = ['month'], axis = 1, inplace = True)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_day_of_week(df):\n",
    "    \"\"\"\n",
    "    Encode the day of the week as a cyclic feature\n",
    "    \"\"\"\n",
    "    new_df = df.copy()\n",
    "    new_df['day_of_week'] = pd.to_datetime(new_df['Date']).dt.dayofweek\n",
    "    new_df[\"day_of_week_sin\"] = np.sin(2 * np.pi * new_df[\"day_of_week\"] / 7)\n",
    "    new_df[\"day_of_week_cos\"] = np.cos(2 * np.pi * new_df[\"day_of_week\"] / 7)\n",
    "    new_df.drop(labels = [\"day_of_week\"], axis = 1, inplace = True)\n",
    "    return new_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_holidays(df):\n",
    "    \"\"\"\n",
    "    Encode holidays as a binary feature\n",
    "    \"\"\"\n",
    "    new_df = df.copy()\n",
    "    tx_holidays = holidays.US(state = 'TX')\n",
    "    new_df[\"Is_Holiday\"] = new_df[\"Date\"].apply(lambda x : 1 if x in tx_holidays else 0)\n",
    "    return new_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_cols = ['North Load', 'Houston Load', 'South Load', 'West Load']\n",
    "predicted_load_cols = ['North Predicted Load', 'Houston Predicted Load', 'South Predicted Load', 'West Predicted Load']\n",
    "df_1 = create_lagged_features(df, price_cols_and_lags, load_cols_and_lags)\n",
    "df_2 = create_ema_mean_and_sd(df_1, ema_cols)\n",
    "df_3 = create_pairwise_differences_and_lags(df_2, ['North Price', 'Houston Price', 'South Price', 'West Price'])\n",
    "df_4 = delete_rows_with_missing_values(df_3)\n",
    "df_5 = encode_month(df_4)\n",
    "df_6 = encode_day_of_week(df_5)\n",
    "df_7 = encode_holidays(df_6)\n",
    "df_final = delete_predicted_load(df_7, load_cols, predicted_load_cols, 168)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_scale = [col for col in df_final if col not in ['Date', 'Time','month_sin', 'month_cos', 'day_of_week_sin', 'day_of_week_cos', 'Is_Holiday']]\n",
    "def scale_data(df, columns_to_scale):\n",
    "    \"\"\"\n",
    "    Scale the data using StandardScaler\n",
    "    \"\"\"\n",
    "    new_df = df.copy()\n",
    "    scaler = StandardScaler()\n",
    "    new_df[columns_to_scale] = scaler.fit_transform(new_df[columns_to_scale])\n",
    "    return (new_df, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_scale_data(df, columns_to_scale, test_size=168):\n",
    "    \"\"\"\n",
    "    Split the data into training and test sets, and scale the numerical features.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The input DataFrame containing the data.\n",
    "    columns_to_scale (list): List of column names to be scaled.\n",
    "    test_size (int, optional): The number of rows to be used as the test set. Default is 168.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: A tuple containing the scaled training DataFrame, scaled test DataFrame, and the scaler object.\n",
    "    \"\"\"\n",
    "    df_train = df.iloc[:-test_size]\n",
    "    df_test = df.iloc[-test_size:]\n",
    "    \n",
    "    df_train_scaled, scaler = scale_data(df_train, columns_to_scale)\n",
    "    df_test_scaled = df_test.copy()\n",
    "    df_test_scaled[columns_to_scale] = scaler.transform(df_test[columns_to_scale])\n",
    "    \n",
    "    return df_train_scaled, df_test_scaled, scaler\n",
    "\n",
    "df_train_scaled, df_test_scaled, scaler = split_and_scale_data(df_final, columns_to_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
